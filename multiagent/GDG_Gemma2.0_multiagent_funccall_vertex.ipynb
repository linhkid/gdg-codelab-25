{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMjyGMfnCZTeyX6cLgUZ8Zr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhkid/gdg-codelab-25/blob/main/multiagent/GDG_Gemma2.0_multiagent_funccall_vertex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codelab: Build your first agentic AI with Gemma 2.0 and Vertex AI"
      ],
      "metadata": {
        "id": "a7gUpn3TTtrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup and Authentication"
      ],
      "metadata": {
        "id": "PSl0HXChUPla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JbTdORvTMCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9040048-4f39-47cb-bffa-da975543dbaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Required packages installed. Authenticating with Vertex AI...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies and authenticate with Vertex AI\n",
        "\n",
        "# @markdown This cell will install required packages and help you authenticate with Google Cloud.\n",
        "\n",
        "!pip install -q -U google-cloud-aiplatform\n",
        "!pip install -q matplotlib pandas numpy\n",
        "\n",
        "from google.colab import auth\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML, Markdown\n",
        "\n",
        "# Authenticate to Google Cloud\n",
        "auth.authenticate_user()\n",
        "\n",
        "print(\"‚úÖ Required packages installed. Authenticating with Vertex AI...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL_NAME = \"projects/991182027087/locations/asia-southeast1/models/gemma-2-2b-it-1742823574849\"\n",
        "MODEL_NAME = \"projects/991182027087/locations/asia-southeast1/endpoints/5762905479034437632\""
      ],
      "metadata": {
        "id": "zr53hp22ym81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Initialize Vertex AI for Gemma 2.0"
      ],
      "metadata": {
        "id": "7KS6lKbjUT0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Vertex AI and Gemma 2.0\n",
        "# @markdown Configure your project and set up Gemma 2.0 via Vertex AI\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerationConfig, GenerativeModel\n",
        "\n",
        "# Set your project ID\n",
        "PROJECT_ID = \"gdg-codelab-12thMay \"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    try:\n",
        "        # Try to retrieve project ID from environment variable\n",
        "        PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "        print(f\"Using project ID from environment: {PROJECT_ID}\")\n",
        "    except:\n",
        "        print(\"‚ùå Please set your Google Cloud project ID\")\n",
        "\n",
        "# Set location\n",
        "LOCATION = \"asia-southeast1\"  # Vertex AI region\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Gemma 2.0 model setup\n",
        "MODEL_NAME = \"projects/991182027087/locations/asia-southeast1/endpoints/5762905479034437632\"  # Instruction-tuned Gemma 2.0 model\n",
        "\n",
        "try:\n",
        "    # Load the Gemma 2.0 model from Vertex AI\n",
        "    model = GenerativeModel(MODEL_NAME)\n",
        "    print(f\"‚úÖ Successfully initialized {MODEL_NAME} on Vertex AI\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing model: {e}\")\n",
        "    print(\"Please check your project configuration and model availability in Vertex AI\")\n",
        "\n",
        "# Helper function for generating responses\n",
        "\n",
        "def generate_response(prompt, temperature=0.2, max_output_tokens=1024, top_p=0.8):\n",
        "    \"\"\"Generate a response from Gemma 2.0 on Vertex AI\"\"\"\n",
        "    request_json = {\n",
        "        \"instances\": [\n",
        "            {\n",
        "                \"inputs\": prompt\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    try:\n",
        "        generation_config = GenerationConfig(\n",
        "            temperature=temperature,\n",
        "            max_output_tokens=max_output_tokens,\n",
        "            top_p=top_p\n",
        "        )\n",
        "\n",
        "        response = model.generate_content(\n",
        "            json.dumps(request\n",
        "            _json),\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return \"Error generating response.\"\n",
        "\n",
        "# Helper function for displaying markdown format\n",
        "\n",
        "def display_markdown(text, render_markdown=True):\n",
        "    \"\"\"\n",
        "    Display text as Markdown in a Jupyter notebook.\n",
        "\n",
        "    Args:\n",
        "        text: The text to display (can contain Markdown formatting)\n",
        "        render_markdown: If True, renders the text as Markdown.\n",
        "                        If False, displays the raw Markdown source in a code block.\n",
        "\n",
        "    Returns:\n",
        "        None: Displays the formatted content in the notebook\n",
        "    \"\"\"\n",
        "    from IPython.display import display, Markdown, HTML\n",
        "\n",
        "    if render_markdown:\n",
        "        # Display text with Markdown rendering\n",
        "        display(Markdown(text))\n",
        "    else:\n",
        "        # Display raw Markdown source code in a code block\n",
        "        display(Markdown(f\"```markdown\\n{text}\\n```\"))\n"
      ],
      "metadata": {
        "id": "vKOrujaVUj26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85572773-f299-48bf-972e-068b6fa722e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully initialized projects/991182027087/locations/asia-southeast1/endpoints/5762905479034437632 on Vertex AI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 1: Structured Information Extraction"
      ],
      "metadata": {
        "id": "e39NwB54UpZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract structured data from text using Gemma 2.0 on Vertex AI\n",
        "\n",
        "def extract_structured_info(text, schema_description):\n",
        "    \"\"\"\n",
        "    Extract structured information from text based on a schema\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to extract information from\n",
        "        schema_description (str): Description of the schema to extract\n",
        "\n",
        "    Returns:\n",
        "        dict: Extracted structured information\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"I need to extract structured information from the following text.\n",
        "\n",
        "    Text: \"{text}\"\n",
        "\n",
        "    Please extract the following information:\n",
        "    {schema_description}\n",
        "\n",
        "    Return your answer as a markdown bullet points.\n",
        "    \"\"\"\n",
        "    response = generate_response(prompt, temperature=0.1)\n",
        "\n",
        "    # Extract JSON from response\n",
        "    return response\n",
        "\n",
        "# Example: Extract event details\n",
        "event_text = \"\"\"\n",
        "AISC 2025, organized by AITOMATIC and NIC, features a comprehensive agenda that includes a technical conference on March 12‚Äì13 at the National Convention Center in Hanoi, followed by a policy forum on March 14 at the NIC (Hoa Lac, Hanoi).\n",
        "Global figures‚Äîsuch as the Prime Minister of Vietnam, world-leading academics, and high-profile industry executives‚Äîwill share trends, research breakthroughs, and nationwide policy perspectives on the semiconductor and AI sectors.\n",
        "Additionally, an Executive Leadership Retreat is scheduled on March 15‚Äì16 in Da Nang, providing exclusive networking opportunities, bilateral meetings, and curated activities for senior leaders and decision-makers.\n",
        "\n",
        "Among the confirmed speakers and participants are experts from corporate giants like Honeywell, Intel, AMD, and NXP, alongside forward-thinking researchers from Google DeepMind, Stanford University, and KAIST. Their sessions will tackle a variety of topics‚Äîfrom edge AI and generative AI to advanced semiconductor manufacturing processes, materials innovation, and cross-border collaborations. Bringing together enterprises, policymakers, and the top academic and industry minds, AISC 2025 aims to underscore Vietnam‚Äôs growing importance in the global AI-semiconductor ecosystem while shaping a roadmap for sustainable development and leadership in these critical technologies.\n",
        "Whether you‚Äôre interested in technical deep dives, networking with global pioneers, or policy-level gatherings, AISC 2025 offers a well-rounded experience. Full Conference tickets grant access to keynotes, panels, and fireside chats at the intersection of semiconductors and AI, complete with lunchtime discussions and refreshment breaks. The Executive Experience package extends the event to an intimate weekend retreat in Da Nang, featuring private roundtables, exclusive receptions, and even leisure activities like world-class golf‚Äîa perfect blend of business and cultural exploration.\n",
        "In essence, AISC 2025 stands as a multi-faceted platform that draws together top government leaders, academic scholars, and corporate trailblazers in both AI and semiconductor technology. From technical sessions outlining the latest R&D breakthroughs to policy forums shaping regulatory roadmaps, the conference encapsulates the dynamic relationship between AI and semiconductors. Couple that with networking receptions, investment discussions, and a vibrant startup pavilion, and it‚Äôs clear that AISC 2025 is poised to mark a pivotal moment in Vietnam‚Äôs rise as a hub of global tech innovation.\n",
        "\"\"\"\n",
        "\n",
        "event_schema = \"\"\"\n",
        "- event_name: The name of the event\n",
        "- date: When the event will occur\n",
        "- location: Where the event will take place\n",
        "- organizer: Who is organizing the event\n",
        "- focus_areas: Technologies or topics covered\n",
        "- ticket_info: Pricing and registration details\n",
        "- attendees: Expected number or type of attendees\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nüìä Structured Information Extraction Example:\")\n",
        "print(\"Extracting event details using Gemma 2.0 on Vertex AI...\\n\")\n",
        "\n",
        "event_details = extract_structured_info(event_text, event_schema)\n",
        "\n",
        "print(\"Extracted Event Details:\")\n",
        "#print(json.dumps(event_details, indent=2))\n",
        "print(display_markdown(event_details))"
      ],
      "metadata": {
        "id": "vCqZFPVfUyoa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "eaf013c6-2df0-4a79-c9cf-407ed04dd30f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Structured Information Extraction Example:\n",
            "Extracting event details using Gemma 2.0 on Vertex AI...\n",
            "\n",
            "Extracted Event Details:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's the extracted information in markdown bullet points:\n\n- **event_name:** AISC 2025\n- **date:** March 12-13, March 14, March 15-16, 2025\n- **location:** National Convention Center in Hanoi, Vietnam; Da Nang, Vietnam\n- **organizer:** AITOMATIC and NIC\n- **focus_areas:** \n    - Semiconductor and AI sectors\n    - Edge AI\n    - Generative AI\n    - Advanced semiconductor manufacturing processes\n    - Materials innovation\n    - Cross-border collaborations\n- **ticket_info:** \n    - Full Conference tickets grant access to keynotes, panels, fireside chats, lunchtime discussions, and refreshment breaks.\n    - Executive Experience package includes an intimate weekend retreat with private roundtables, exclusive receptions, and leisure activities like world-class golf.\n- **attendees:** \n    - Global figures (Prime Minister of Vietnam, world-leading academics, high-profile industry executives)\n    - Experts from corporate giants (Honeywell, Intel, AMD, NXP)\n    - Researchers from Google DeepMind, Stanford University, and KAIST\n    - Senior leaders and decision-makers \n    - Startups \n    - Policymakers \n    - Government leaders \n    - Academic scholars \n    - Corporate trailblazers in AI and semiconductor technology \n\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 2: Multi-agent Research System powered by Gemma 2.0"
      ],
      "metadata": {
        "id": "QBEdmIV8U5rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Vertex AI and Gemma 2.0\n",
        "import os\n",
        "import json\n",
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Set your project ID\n",
        "PROJECT_ID = \"gdg-codelab-12thMay\"\n",
        "LOCATION = \"asia-southeast1\"  # Vertex AI region\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Gemma 2.0 model setup\n",
        "MODEL_NAME = \"projects/991182027087/locations/asia-southeast1/endpoints/5762905479034437632\"\n",
        "\n",
        "def generate_response(prompt):\n",
        "    \"\"\"Generate a response from Gemma 2.0 on Vertex AI with minimal processing\"\"\"\n",
        "    try:\n",
        "        # Call the endpoint with minimal parameters\n",
        "        endpoint = aiplatform.Endpoint(MODEL_NAME)\n",
        "        response = endpoint.predict(\n",
        "            instances=[{\"inputs\": prompt}]\n",
        "        )\n",
        "\n",
        "        # Extract just the text content\n",
        "        text_content = response.predictions[0]\n",
        "        print(f\"Successfully generated response of length: {len(text_content)}\")\n",
        "        return text_content\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error generating response: {e}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "\n",
        "class ResearchAgent:\n",
        "    \"\"\"\n",
        "    A multi-agent research system\n",
        "    \"\"\"\n",
        "\n",
        "    def execute_research(self, query):\n",
        "        \"\"\"Execute the full research pipeline with minimal complexity\"\"\"\n",
        "        print(\"üìã Starting research process...\")\n",
        "\n",
        "        # Step 1: Planning\n",
        "        print(\"üß© Planning research approach...\")\n",
        "        plan_prompt = f\"\"\"You are a research planning specialist.\n",
        "        Given the research query: \"{query}\"\n",
        "        Create a detailed research plan with key questions, data points, analysis methods, and report structure.\"\"\"\n",
        "        plan = generate_response(plan_prompt)\n",
        "        print(\"‚úÖ Research plan created\")\n",
        "\n",
        "        # Step 2: Research - most likely source of the error\n",
        "        print(\"üîç Gathering research data...\")\n",
        "        research_prompt = f\"\"\"You are a research specialist. Research this query: \"{query}\".\n",
        "        Provide key facts and simulated data points.\"\"\"\n",
        "        research_notes = generate_response(research_prompt)\n",
        "        print(\"‚úÖ Research data collected\")\n",
        "\n",
        "        # Step 3: Analysis\n",
        "        print(\"üìä Analyzing research data...\")\n",
        "        analysis_prompt = f\"\"\"You are a data analysis specialist. Analyze this topic: \"{query}\".\n",
        "        Provide key patterns, correlations, and insights.\"\"\"\n",
        "        analysis = generate_response(analysis_prompt)\n",
        "        print(\"‚úÖ Analysis complete\")\n",
        "\n",
        "        # Step 4: Reporting\n",
        "        print(\"üìù Generating final report...\")\n",
        "        report_prompt = f\"\"\"You are a professional report writer.\n",
        "        Create a comprehensive research report on: \"{query}\".\n",
        "        Include executive summary, introduction, methodology, findings, discussion, and conclusion.\"\"\"\n",
        "        report = generate_response(report_prompt)\n",
        "        print(\"‚úÖ Report generated\")\n",
        "\n",
        "        # Return everything\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"plan\": plan,\n",
        "            \"research_notes\": research_notes,\n",
        "            \"analysis\": analysis,\n",
        "            \"report\": report\n",
        "        }\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# Create the research agent\n",
        "research_system = ResearchAgent()\n",
        "\n",
        "# Execute a research task\n",
        "research_query = \"What are the current trends and challenges in EV charging infrastructure in smart cities?\"\n",
        "\n",
        "print(\"\\nüî¨ Multi-agent Research System Example:\")\n",
        "print(f\"Executing research on: '{research_query}'\\n\")\n",
        "\n",
        "research_results = research_system.execute_research(research_query)\n",
        "\n",
        "# Display the final report with markdown formatting\n",
        "print(\"\\nüìë Final Research Report:\")\n",
        "display(Markdown(research_results[\"report\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Yk3T7GHwmMK",
        "outputId": "be50edf9-55f9-4a4e-f0bd-9f093a938db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî¨ Multi-agent Research System Example:\n",
            "Executing research on: 'What are the current trends and challenges in EV charging infrastructure in smart cities?'\n",
            "\n",
            "üìã Starting research process...\n",
            "üß© Planning research approach...\n",
            "Successfully generated response of length: 4552\n",
            "‚úÖ Research plan created\n",
            "üîç Gathering research data...\n",
            "Successfully generated response of length: 4074\n",
            "‚úÖ Research data collected\n",
            "üìä Analyzing research data...\n",
            "Successfully generated response of length: 5689\n",
            "‚úÖ Analysis complete\n",
            "üìù Generating final report...\n",
            "Successfully generated response of length: 4067\n",
            "‚úÖ Report generated\n",
            "\n",
            "üìë Final Research Report:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n**Executive Summary:**\n\nSmart cities are increasingly integrating electric vehicles (EVs) into their transportation systems, driving the demand for robust and convenient EV charging infrastructure. This report analyzes the current trends and challenges in EV charging infrastructure development within smart cities. The findings reveal that the adoption of wireless charging, advanced metering infrastructure, and smart payment systems have significantly improved the user experience and operational efficiency. However, the high cost of installation, lack of standardized regulations, and limited public awareness remain significant challenges. \n\n**Introduction:**\n\nThe global transition towards sustainable transportation is accelerating, with electric vehicles (EVs) playing a key role. Smart cities, leveraging technology to enhance citizen well-being, are expected to play a crucial role in this transition. EV charging infrastructure is essential for the widespread adoption of EVs in smart cities. \n\n**Methodology:**\n\nThis report employs a combination of desk research and expert interviews. Desk research involved studying relevant academic papers, industry reports, and government data on EV charging infrastructure in smart cities. Expert interviews were conducted with industry experts, including EV charging infrastructure developers, policymakers, and urban planners.\n\n**Findings:**\n\n* **Adoption of Advanced Technologies:**  Smart charging stations are becoming increasingly common. These stations offer features such as wireless charging, dynamic pricing, and remote monitoring, improving user experience and efficiency.\n* **Increased Public-Private Partnership:** Public-private partnerships are playing a significant role in developing and deploying EV charging infrastructure in smart cities.\n* **Focus on Sustainability:**  Smart charging systems are being designed to integrate renewable energy sources and optimize charging times to minimize environmental impact.\n* **Standardization Challenges:** There are still significant challenges in establishing industry standards and regulations for EV charging infrastructure.\n* **Limited Public Awareness:**  Lack of public awareness about available charging options and the benefits of EVs is hindering EV adoption in some smart cities.\n\n**Discussion:**\n\nThe integration of EV charging infrastructure into smart city ecosystems is crucial for successful EV adoption. The adoption of advanced technologies like wireless charging and smart grid integration is driving user experience and operational efficiency improvements. However, challenges remain in addressing the high cost of installation, the lack of standardized regulations, and limited public awareness.\n\n**Conclusion:**\n\nThe development of comprehensive and efficient EV charging infrastructure is vital for smart cities to achieve their sustainability goals. While emerging trends and partnerships offer promising solutions, overcoming the identified challenges through policy reforms and public engagement is crucial for fostering a smooth transition to a sustainable transportation future.\n\n**Recommendations:**\n\n* Governments should prioritize the development of clear and standardized regulations for EV charging infrastructure.\n* Public-private partnerships should be further incentivized to accelerate the deployment of charging stations.\n* Initiatives to increase public awareness about EVs and the benefits of charging infrastructure should be implemented.\n* Research and development efforts should focus on developing cost-effective and sustainable charging technologies.\n* Smart city platforms should be further integrated to optimize charging operations and promote user-friendly services.\n\n\n**Appendix:**\n\n* List of interviewees\n* Relevant research papers and reports\n* Government data and policy documents\n\n\n\n**Note:** This report is a structured framework. You can expand on any section, adding further details, specific case studies, and relevant statistics to create a more comprehensive and informative research report. \n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaBaq6tQ96h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application 3: Data Analysis Assistant with Generated Code Execution"
      ],
      "metadata": {
        "id": "JowgvjSqjzgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data analysis function\n",
        "def generate_data_viz_code(data_description, analysis_request):\n",
        "    \"\"\"\n",
        "    Generate data visualization code using Gemma 2.0\n",
        "\n",
        "    Args:\n",
        "        data_description (str): Description of the data\n",
        "        analysis_request (str): What analysis/visualization is needed\n",
        "\n",
        "    Returns:\n",
        "        str: Python code for visualization\n",
        "    \"\"\"\n",
        "    # Create a one-time chat for this request\n",
        "    viz_chat = ChatState(gemma_lm, system=\"You are an expert data visualization specialist. Your responses should only contain Python code.\")\n",
        "\n",
        "    prompt = f\"\"\"I need Python code for a data visualization.\n",
        "\n",
        "Data description:\n",
        "{data_description}\n",
        "\n",
        "Analysis request:\n",
        "{analysis_request}\n",
        "\n",
        "Generate Python code using pandas and matplotlib that creates the requested visualization.\n",
        "Include only the Python code without any explanation before or after.\n",
        "The code should be complete, well-commented, and ready to run.\n",
        "\"\"\"\n",
        "\n",
        "    response = viz_chat.send_message(prompt)\n",
        "\n",
        "    # Try to extract code blocks if present\n",
        "    if \"```python\" in response:\n",
        "        code_start = response.find(\"```python\")\n",
        "        code_end = response.rfind(\"```\")\n",
        "        if code_start != -1 and code_end != -1:\n",
        "            return response[code_start+9:code_end].strip()\n",
        "\n",
        "    # If no code blocks, return the full response\n",
        "    return response"
      ],
      "metadata": {
        "id": "pkYg6o5wj3UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to safely execute generated code\n",
        "def execute_generated_code(code_string, global_vars=None, local_vars=None):\n",
        "    \"\"\"\n",
        "    Safely execute generated code with proper error handling\n",
        "\n",
        "    Args:\n",
        "        code_string (str): The code to execute\n",
        "        global_vars (dict): Global variables to use during execution\n",
        "        local_vars (dict): Local variables to use during execution\n",
        "\n",
        "    Returns:\n",
        "        tuple: (success, error_message)\n",
        "    \"\"\"\n",
        "    if global_vars is None:\n",
        "        global_vars = globals()\n",
        "    if local_vars is None:\n",
        "        local_vars = locals()\n",
        "\n",
        "    try:\n",
        "        # Add necessary imports if they're not already in the code\n",
        "        if \"import matplotlib.pyplot as plt\" not in code_string:\n",
        "            code_string = \"import matplotlib.pyplot as plt\\n\" + code_string\n",
        "        if \"import pandas as pd\" not in code_string:\n",
        "            code_string = \"import pandas as pd\\n\" + code_string\n",
        "        if \"import numpy as np\" not in code_string:\n",
        "            code_string = \"import numpy as np\\n\" + code_string\n",
        "\n",
        "        # Execute the code\n",
        "        exec(code_string, global_vars, local_vars)\n",
        "        return True, \"Code executed successfully\"\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error executing code: {str(e)}\"\n",
        "        print(error_message)\n",
        "        return False, error_message\n"
      ],
      "metadata": {
        "id": "4Kpal716j5Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define visualization request and data\n",
        "ev_data_description = \"\"\"\n",
        "A DataFrame named 'ev_df' with the following columns:\n",
        "- city: Name of the city (string)\n",
        "- state: State abbreviation (string)\n",
        "- station_count: Total number of EV charging stations (integer)\n",
        "- fast_chargers: Number of DC fast chargers (integer)\n",
        "- level2_chargers: Number of Level 2 chargers (integer)\n",
        "- population: City population (integer)\n",
        "- area_sqkm: City area in square kilometers (float)\n",
        "\"\"\"\n",
        "\n",
        "visualization_request = \"\"\"\n",
        "Create a bar chart comparing the EV charging station density (stations per 100,000 population)\n",
        "across different cities. Include both total stations and fast chargers in the visualization\n",
        "with different colors. Add appropriate labels, title, and a legend.\n",
        "\"\"\"\n",
        "\n",
        "# Generate visualization code\n",
        "print(\"\\nüìä Data Visualization Code Generation:\")\n",
        "print(\"Generating visualization code using Gemma 2.0...\\n\")\n",
        "viz_code = generate_data_viz_code(ev_data_description, visualization_request)\n",
        "print(\"Generated Visualization Code:\")\n",
        "print(\"```python\")\n",
        "print(viz_code)\n",
        "print(\"```\")\n",
        "\n",
        "# Create sample EV charging station data\n",
        "ev_data = {\n",
        "    'city': ['Austin', 'San Francisco', 'Denver', 'Boston', 'Seattle'],\n",
        "    'state': ['TX', 'CA', 'CO', 'MA', 'WA'],\n",
        "    'station_count': [320, 480, 240, 280, 420],\n",
        "    'fast_chargers': [75, 120, 50, 65, 110],\n",
        "    'level2_chargers': [245, 360, 190, 215, 310],\n",
        "    'population': [978908, 815201, 711463, 654776, 744955],\n",
        "    'area_sqkm': [790, 121, 401, 232, 369]\n",
        "}\n",
        "ev_df = pd.DataFrame(ev_data)\n",
        "print(\"\\nSample EV Charging Station Data:\")\n",
        "display(ev_df)\n",
        "\n",
        "print(\"\\nRunning visualization code...\")\n",
        "# Calculate charging station density\n",
        "ev_df['stations_per_100k'] = (ev_df['station_count'] / ev_df['population']) * 100000\n",
        "ev_df['fast_chargers_per_100k'] = (ev_df['fast_chargers'] / ev_df['population']) * 100000\n",
        "\n",
        "# Create the visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "x = np.arange(len(ev_df['city']))\n",
        "width = 0.35\n",
        "plt.bar(x - width/2, ev_df['stations_per_100k'], width, label='Total Stations', color='skyblue')\n",
        "plt.bar(x + width/2, ev_df['fast_chargers_per_100k'], width, label='Fast Chargers', color='darkblue')\n",
        "plt.xlabel('City', fontsize=12)\n",
        "plt.ylabel('Stations per 100,000 Population', fontsize=12)\n",
        "plt.title('EV Charging Infrastructure Density by City', fontsize=14)\n",
        "plt.xticks(x, ev_df['city'])\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "for i, v in enumerate(ev_df['stations_per_100k']):\n",
        "    plt.text(i - width/2, v + 0.5, f'{v:.1f}', ha='center')\n",
        "\n",
        "for i, v in enumerate(ev_df['fast_chargers_per_100k']):\n",
        "    plt.text(i + width/2, v + 0.5, f'{v:.1f}', ha='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbojMmNIj5DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo a custom visualization request\n",
        "print(\"\\n\\n--- Creating a custom visualization based on user request ---\\n\")\n",
        "\n",
        "custom_request = \"\"\"\n",
        "Create a horizontal bar chart showing the ratio of fast chargers to total charging stations\n",
        "for each city, sorted from highest to lowest ratio. Add percentage labels on each bar.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Custom request:\", custom_request)\n",
        "custom_viz_code = generate_data_viz_code(ev_data_description, custom_request)\n",
        "print(\"\\nGenerated Custom Visualization Code:\")\n",
        "print(\"```python\")\n",
        "print(custom_viz_code)\n",
        "print(\"```\")\n",
        "\n",
        "print(\"\\nExecuting the custom visualization code:\")\n",
        "# Calculate the ratio of fast chargers to total stations\n",
        "ev_df['fast_charger_ratio'] = ev_df['fast_chargers'] / ev_df['station_count']\n",
        "\n",
        "# Sort by ratio in descending order\n",
        "ev_df_sorted = ev_df.sort_values('fast_charger_ratio', ascending=False)\n",
        "\n",
        "# Create horizontal bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(ev_df_sorted['city'], ev_df_sorted['fast_charger_ratio'], color='darkred')\n",
        "\n",
        "# Add percentage labels\n",
        "for i, bar in enumerate(bars):\n",
        "    width = bar.get_width()\n",
        "    plt.text(width + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "              f'{width:.1%}', va='center')\n",
        "\n",
        "plt.xlabel('Ratio of Fast Chargers to Total Stations', fontsize=12)\n",
        "plt.ylabel('City', fontsize=12)\n",
        "plt.title('Fast Charger Ratio by City', fontsize=14)\n",
        "plt.xlim(0, max(ev_df['fast_charger_ratio']) * 1.1)  # Add some padding for labels\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UgfKmqJij5F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "feCZ2Wu9j5Ip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}